{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['active' 'brown' 'cat' 'dog' 'good' 'lazy']\n",
      "[[0.         0.         0.         0.55645052 0.83088075 0.        ]\n",
      " [0.         0.         0.         0.55645052 0.         0.83088075]\n",
      " [0.         0.76944707 0.63871058 0.         0.         0.        ]\n",
      " [0.83088075 0.         0.55645052 0.         0.         0.        ]\n",
      " [0.         0.64846263 0.53828256 0.53828256 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pandas as pd\n",
    "\n",
    "df = [\"He is a good dog.\", \"The dog is too lazy.\",\n",
    "         \"That is a brown cat.\", \"The cat is very active.\", \"I have brown cat and dog.\"]\n",
    "\n",
    "tv = TfidfVectorizer(stop_words='english', smooth_idf=True)\n",
    "\n",
    "tv_fit = tv.fit_transform(df)\n",
    "# 原始单词文本矩阵\n",
    "print(tv.get_feature_names_out())\n",
    "print(tv_fit.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>active</th>\n",
       "      <td>0.200354</td>\n",
       "      <td>-0.242441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brown</th>\n",
       "      <td>0.596512</td>\n",
       "      <td>-0.201810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.629338</td>\n",
       "      <td>-0.329886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.415831</td>\n",
       "      <td>0.616903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0.132383</td>\n",
       "      <td>0.453377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lazy</th>\n",
       "      <td>0.132383</td>\n",
       "      <td>0.453377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic_1   topic_2\n",
       "active  0.200354 -0.242441\n",
       "brown   0.596512 -0.201810\n",
       "cat     0.629338 -0.329886\n",
       "dog     0.415831  0.616903\n",
       "good    0.132383  0.453377\n",
       "lazy    0.132383  0.453377"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVD represent documents and terms in vectors\n",
    "svd_model = TruncatedSVD(n_components=2, algorithm='randomized', n_iter=100)\n",
    "lsa = svd_model.fit_transform(tv_fit)\n",
    "\n",
    "dictionary = tv.get_feature_names_out()\n",
    "encoding_matrix = pd.DataFrame(svd_model.components_, index = [\"topic_1\",\"topic_2\"], columns = (dictionary)).T\n",
    "dictionary\n",
    "encoding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "raw_documents = [\n",
    "    \"He is a good dog.\",\n",
    "    \"The dog is too lazy.\",\n",
    "    \"That is a brown cat.\",\n",
    "    \"The cat is very active.\",\n",
    "    \"I have brown cat and dog.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据：\n",
      "               raw_documents\n",
      "0          He is a good dog.\n",
      "1       The dog is too lazy.\n",
      "2       That is a brown cat.\n",
      "3    The cat is very active.\n",
      "4  I have brown cat and dog.\n"
     ]
    }
   ],
   "source": [
    "# 转为 DataFrame\n",
    "df = pd.DataFrame({'raw_documents': raw_documents})\n",
    "print(\"原始数据：\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn 英文停用词（部分）： ['move', 'a', 'to', 'though', 'sometimes', 'ever', 'neither', 'thus', 'however', 'perhaps']\n"
     ]
    }
   ],
   "source": [
    "# 获取 sklearn 内置的英文停用词（更完整）\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "print(\"Sklearn 英文停用词（部分）：\", list(ENGLISH_STOP_WORDS)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    预处理函数：去标点、转小写、分词、去除停用词、重新组合\n",
    "    \"\"\"\n",
    "    # 1. 转小写\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. 去除标点符号（保留字母和空格）\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # 3. 分词（按空格切分）\n",
    "    words = text.split()\n",
    "    \n",
    "    # 4. 去除停用词\n",
    "    words_clean = [word for word in words if word not in ENGLISH_STOP_WORDS]\n",
    "    \n",
    "    # 5. 重新组合成字符串\n",
    "    return ' '.join(words_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗后的数据：\n",
      "               raw_documents clean_documents\n",
      "0          He is a good dog.        good dog\n",
      "1       The dog is too lazy.        dog lazy\n",
      "2       That is a brown cat.       brown cat\n",
      "3    The cat is very active.      cat active\n",
      "4  I have brown cat and dog.   brown cat dog\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 应用预处理函数\n",
    "df['clean_documents'] = df['raw_documents'].apply(preprocess_text)\n",
    "\n",
    "print(\"清洗后的数据：\")\n",
    "print(df[['raw_documents', 'clean_documents']])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词汇表（词汇 -> 对应的列索引）:\n",
      "{'good': 4, 'dog': 3, 'lazy': 5, 'brown': 1, 'cat': 2, 'active': 0}\n",
      "\n",
      "TF-IDF 矩阵（每一行是一个文档的向量表示）:\n",
      "[[0.         0.         0.         0.55645052 0.83088075 0.        ]\n",
      " [0.         0.         0.         0.55645052 0.         0.83088075]\n",
      " [0.         0.76944707 0.63871058 0.         0.         0.        ]\n",
      " [0.83088075 0.         0.55645052 0.         0.         0.        ]\n",
      " [0.         0.64846263 0.53828256 0.53828256 0.         0.        ]]\n",
      "\n",
      "TF-IDF 矩阵（DataFrame 形式）:\n",
      "              active              brown                cat                dog  \\\n",
      "0 0.0000000000000000 0.0000000000000000 0.0000000000000000 0.5560000000000000   \n",
      "1 0.0000000000000000 0.0000000000000000 0.0000000000000000 0.5560000000000000   \n",
      "2 0.0000000000000000 0.7690000000000000 0.6390000000000000 0.0000000000000000   \n",
      "3 0.8310000000000000 0.0000000000000000 0.5560000000000000 0.0000000000000000   \n",
      "4 0.0000000000000000 0.6480000000000000 0.5380000000000000 0.5380000000000000   \n",
      "\n",
      "                good               lazy  \n",
      "0 0.8310000000000000 0.0000000000000000  \n",
      "1 0.0000000000000000 0.8310000000000000  \n",
      "2 0.0000000000000000 0.0000000000000000  \n",
      "3 0.0000000000000000 0.0000000000000000  \n",
      "4 0.0000000000000000 0.0000000000000000  \n"
     ]
    }
   ],
   "source": [
    "# 构建 TfidfVectorizer 矩阵\n",
    "# 使用 TfidfVectorizer（注意：这里也可以不再去停用词，因为我们已经预处理过了）\n",
    "vectorizer = TfidfVectorizer(smooth_idf=True)  # 已清洗，无需再设 stop_words\n",
    "X = vectorizer.fit_transform(df['clean_documents'])\n",
    "\n",
    "# 查看词汇表\n",
    "print(\"词汇表（词汇 -> 对应的列索引）:\")\n",
    "print(vectorizer.vocabulary_)\n",
    "print()\n",
    "\n",
    "# 查看 TF-IDF 矩阵（转为数组）\n",
    "print(\"TF-IDF 矩阵（每一行是一个文档的向量表示）:\")\n",
    "print(X.toarray())\n",
    "print()\n",
    "\n",
    "# 转为 DataFrame 更直观\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "df_tfidf = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "print(\"TF-IDF 矩阵（DataFrame 形式）:\")\n",
    "print(df_tfidf.round(3))  # 保留三位小数便于查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x6 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', smooth_idf=True)\n",
    "X = vectorizer.fit_transform(df['clean_documents'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['active', 'brown', 'cat', 'dog', 'good', 'lazy'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.55645052, 0.83088075,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.55645052, 0.        ,\n",
       "        0.83088075],\n",
       "       [0.        , 0.76944707, 0.63871058, 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.83088075, 0.        , 0.55645052, 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.64846263, 0.53828256, 0.53828256, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD 分解，假设有 2 个主题\n",
    "# SVD represent documents and terms in vectors \n",
    "svd_model = TruncatedSVD(n_components=2, algorithm='randomized', n_iter=100)\n",
    "lsa = svd_model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = vectorizer.get_feature_names_out()\n",
    "encoding_matrix = pd.DataFrame(svd_model.components_, index = [\"topic_1\",\"topic_2\"], columns = (dictionary)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>active</th>\n",
       "      <td>0.2003541259081117</td>\n",
       "      <td>-0.2424408501618362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brown</th>\n",
       "      <td>0.5965117122287048</td>\n",
       "      <td>-0.2018098984872578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.6293380994160956</td>\n",
       "      <td>-0.3298859088715316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.4158307960649448</td>\n",
       "      <td>0.6169033286639758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0.1323826028466490</td>\n",
       "      <td>0.4533766476433695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lazy</th>\n",
       "      <td>0.1323826028466497</td>\n",
       "      <td>0.4533766476433689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  topic_1             topic_2\n",
       "active 0.2003541259081117 -0.2424408501618362\n",
       "brown  0.5965117122287048 -0.2018098984872578\n",
       "cat    0.6293380994160956 -0.3298859088715316\n",
       "dog    0.4158307960649448  0.6169033286639758\n",
       "good   0.1323826028466490  0.4533766476433695\n",
       "lazy   0.1323826028466497  0.4533766476433689"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary\n",
    "encoding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good dog</td>\n",
       "      <td>0.3413834191239962</td>\n",
       "      <td>0.7199781067501037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog lazy</td>\n",
       "      <td>0.3413834191239967</td>\n",
       "      <td>0.7199781067501032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brown cat</td>\n",
       "      <td>0.8609490919302170</td>\n",
       "      <td>-0.3659836550739513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat active</td>\n",
       "      <td>0.5166658991993216</td>\n",
       "      <td>-0.3850046207843261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brown cat dog</td>\n",
       "      <td>0.9494117370834869</td>\n",
       "      <td>0.0236302940661150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       documents            topic_1             topic_2\n",
       "0       good dog 0.3413834191239962  0.7199781067501037\n",
       "1       dog lazy 0.3413834191239967  0.7199781067501032\n",
       "2      brown cat 0.8609490919302170 -0.3659836550739513\n",
       "3     cat active 0.5166658991993216 -0.3850046207843261\n",
       "4  brown cat dog 0.9494117370834869  0.0236302940661150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.16f}'.format\n",
    "topic_encoded_df = pd.DataFrame(lsa, columns = [\"topic_1\", \"topic_2\"])\n",
    "topic_encoded_df[\"documents\"] = df['clean_documents']\n",
    "display(topic_encoded_df[[\"documents\", \"topic_1\", \"topic_2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.8",
   "language": "python",
   "name": "pytorch2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
